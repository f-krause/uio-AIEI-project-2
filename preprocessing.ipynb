{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T13:06:46.536441600Z",
     "start_time": "2023-10-27T13:06:44.222909900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T13:06:48.900827700Z",
     "start_time": "2023-10-27T13:06:47.653846600Z"
    }
   },
   "outputs": [],
   "source": [
    "# NB: this requires openpyxl to be installed\n",
    "xl = pd.ExcelFile(\"./data/Dataset.xlsx\")\n",
    "# extract sheets that start with consumer\n",
    "consumer_sheets = [name for name in xl.sheet_names\n",
    "                   if name.startswith(\"Consumer\")]\n",
    "# TODO: take all consumer sheets, not only the first 10 (= delete next line)\n",
    "#consumer_sheets = consumer_sheets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of dataset for task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T13:11:08.652182300Z",
     "start_time": "2023-10-27T13:06:50.548935300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:01<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# mapping consumer to DataFrame containing tabular data\n",
    "cons2df = {name: xl.parse(name).drop(columns=[\"Unnamed: 0\",\"Total Consumption\"])\n",
    "           for name in tqdm(consumer_sheets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T13:30:36.252345200Z",
     "start_time": "2023-10-27T13:30:35.664948400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AC', 'Dish washer', 'Washing Machine', 'Dryer', 'Water heater', 'TV', 'Microwave', 'Kettle', 'Lighting', 'Refrigerator', 'Total Consumption']\n"
     ]
    }
   ],
   "source": [
    "# sum over all columns that are not Periods (which is at index 0)\n",
    "sum_cols = cons2df[\"Consumer1\"].columns[1:].tolist()\n",
    "print(sum_cols)\n",
    "for name, df in cons2df.items():\n",
    "    df[\"Total Consumption\"] = df[sum_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants based on 15min intervals\n",
    "day_length = 4 * 24\n",
    "week_window = day_length * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 366)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export total consumption data individually\n",
    "total_consumptions = []\n",
    "for household_ix, df in enumerate(cons2df.values()):\n",
    "  total_consumptions.append(df[\"Total Consumption\"].values)\n",
    "# create a numpy array of shape (H, L), where L is the total number of\n",
    "# consumption values available for a household\n",
    "total_consumptions = np.stack(total_consumptions)\n",
    "daily_consumptions = (\n",
    "  # first group the consumption values by day and then sum over the values of\n",
    "  # each day to get the total consumption per day\n",
    "  total_consumptions.reshape(len(cons2df), -1, day_length).sum(-1)\n",
    ")\n",
    "np.savez(\"./data/daily_consumptions\", daily_consumptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T10:11:59.205713600Z",
     "start_time": "2023-10-27T10:11:57.377371500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((359, 50, 7), (359, 50))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over DataFrames and extract x = week -> y = next day pairs\n",
    "xs, ys = [], []\n",
    "for df in cons2df.values():\n",
    "  # extract the total consumption data from the dataset\n",
    "  data = df[\"Total Consumption\"].values\n",
    "\n",
    "  # obtain start and end values of the window\n",
    "  # NB: the window end includes the day to be predicted\n",
    "  starts = np.arange(0, len(data) - week_window - day_length + 1, day_length)\n",
    "  ends = starts + week_window + day_length # end includes the day to predict\n",
    "  cons_xs, cons_ys = [], [] # save data for this consumer\n",
    "  for start, end in zip(starts, ends):\n",
    "    # extract the 8-day window from the dataset\n",
    "    window = data[start:end]\n",
    "    # split the window in week data and the day to predict\n",
    "    x, y = window[:-day_length], window[-day_length:]\n",
    "    # put the samples in the dataset\n",
    "    x_days = 0\n",
    "    # get the consumption per day\n",
    "    week = []\n",
    "    for i in range(0, len(x), day_length):\n",
    "      values = x[i:i+day_length]\n",
    "      week.append(sum(values))\n",
    "    cons_xs.append(week)\n",
    "    cons_ys.append(sum(y))\n",
    "  assert end == len(data) # ensure that we covered all of the input data\n",
    "  xs.append(np.stack(cons_xs))\n",
    "  ys.append(np.stack(cons_ys))\n",
    "# create length dimension\n",
    "xs, ys = np.stack(xs), np.stack(ys)\n",
    "# swap day (=N) and household dimensions such that we can sample days for\n",
    "# dataset creation\n",
    "xs = xs.transpose(1, 0, 2)\n",
    "ys = ys.transpose(1, 0)\n",
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T10:12:04.237935500Z",
     "start_time": "2023-10-27T10:12:04.223993300Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate train/validation/test splits with 80/10/10 ratio\n",
    "xtr, xvalte, ytr, yvalte = train_test_split(xs, ys, test_size=.2, shuffle=False)\n",
    "xval, xte, yval, yte = train_test_split(xvalte, yvalte, test_size=.5, shuffle=False)\n",
    "xtr = xtr.transpose(1, 0, 2)\n",
    "ytr = ytr.transpose(1, 0)\n",
    "xval = xval.transpose(1, 0, 2)\n",
    "yval = yval.transpose(1, 0)\n",
    "xte = xte.transpose(1, 0, 2)\n",
    "yte = yte.transpose(1, 0)\n",
    "xs = xs.transpose(1, 0, 2)\n",
    "ys = ys.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T10:12:06.259748700Z",
     "start_time": "2023-10-27T10:12:06.248580500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez(\"./data/task1_train\", x=xtr, y=ytr)\n",
    "np.savez(\"./data/task1_val\", x=xval, y=yval)\n",
    "np.savez(\"./data/task1_test\", x=xte, y=yte)\n",
    "np.savez(\"./data/task1_data\", x=xs, y=ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Creation of dataset for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:05:14.526978Z",
     "start_time": "2023-10-27T14:00:48.381344900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:26<00:00,  5.32s/it]\n"
     ]
    }
   ],
   "source": [
    "cons2df = {name: xl.parse(name).drop(columns=[\"Unnamed: 0\",\"Periods\",\"Total Consumption\"])\n",
    "           for name in tqdm(consumer_sheets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:35:33.923630500Z",
     "start_time": "2023-10-27T14:34:52.936701900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants based on 15min intervals\n",
    "day_length = 4 * 24\n",
    "mapping = {'AC': 0, 'Dish washer': 1, 'Washing Machine': 2, 'Dryer': 3, 'Water heater': 4, 'TV': 5, 'Microwave': 6, 'Kettle': 7, 'Lighting': 8, 'Refrigerator': 9}\n",
    "\n",
    "# iterate over DataFrames and extract x = week -> y = next day pairs\n",
    "xs, ys = [], []\n",
    "for df in cons2df.values():\n",
    "    cons_xs = []\n",
    "    cons_ys = []\n",
    "    for (appliance, data) in df.items():\n",
    "        day_consumption = []\n",
    "        count = 0\n",
    "        for i in range(len(data)):\n",
    "            if count == day_length:\n",
    "                cons_xs.append(day_consumption)\n",
    "                cons_ys.append(mapping[appliance])\n",
    "                day_consumption = []\n",
    "                count = 0\n",
    "            day_consumption.append(data[i])\n",
    "            count += 1\n",
    "    xs.append(np.stack(cons_xs))\n",
    "    ys.append(np.stack(cons_ys))\n",
    "# create length dimension\n",
    "xs, ys = np.stack(xs), np.stack(ys)\n",
    "# swap day (=N) and household dimensions such that we can sample days for\n",
    "# dataset creation\n",
    "xs = xs.transpose(1, 0, 2)\n",
    "ys = ys.transpose(1, 0)\n",
    "xs.shape, ys.shape\n",
    "xs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:46:02.860681200Z",
     "start_time": "2023-10-27T14:46:02.729888400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate train/validation/test splits with 80/10/10 ratio\n",
    "xtr, xvalte, ytr, yvalte = train_test_split(xs, ys, test_size=.2, shuffle=True)\n",
    "xval, xte, yval, yte = train_test_split(xvalte, yvalte, test_size=.5, shuffle=True)\n",
    "xtr = xtr.transpose(1, 0, 2)\n",
    "ytr = ytr.transpose(1, 0)\n",
    "xval = xval.transpose(1, 0, 2)\n",
    "yval = yval.transpose(1, 0)\n",
    "xte = xte.transpose(1, 0, 2)\n",
    "yte = yte.transpose(1, 0)\n",
    "xs = xs.transpose(1, 0, 2)\n",
    "ys = ys.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:46:05.021688400Z",
     "start_time": "2023-10-27T14:46:04.227028Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez(\"./data/task2_train\", x=xtr, y=ytr)\n",
    "np.savez(\"./data/task2_val\", x=xval, y=yval)\n",
    "np.savez(\"./data/task2_test\", x=xte, y=yte)\n",
    "np.savez(\"./data/task2_data\", x=xs, y=ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4ei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
